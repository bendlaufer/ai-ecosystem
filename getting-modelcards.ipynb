{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try scraping model cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from huggingface_hub import HfApi, snapshot_download, hf_hub_download, ModelCard\n",
    "from huggingface_hub.utils import http_backoff\n",
    "from typing import Dict, Any\n",
    "import backoff\n",
    "\n",
    "HF_TOKEN = userdata.get('HF-TOKEN')\n",
    "\n",
    "!huggingface-cli login --token $HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset_df = pd.read_csv(\"model_dataset_combined_jul12.csv\")\n",
    "model_dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import signal\n",
    "import requests\n",
    "import backoff\n",
    "import threading\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any, Generator\n",
    "from huggingface_hub import HfApi, ModelCard\n",
    "import re\n",
    "\n",
    "import csv\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import requests\n",
    "import threading\n",
    "\n",
    "api = HfApi()\n",
    "model_id = \"apple/DiffuCoder-7B-cpGRPO\"\n",
    "model_dataset_df['model_card'] = \"\"\n",
    "model_dataset_df['metadata'] = \"\"\n",
    "\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"2m_models_with_cards_and_metadata_jul12.csv\"\n",
    "\n",
    "# Function to write a row to the CSV file\n",
    "def write_to_csv(index, model_id, fulljson, metadata, model_card):\n",
    "    with threading.Lock():\n",
    "        with open(csv_file_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([index, model_id, fulljson, metadata, model_card])\n",
    "\n",
    "# Parallelize the fetching of metadata and model cards using ThreadPoolExecutor\n",
    "def fetch_metadata_and_model_card(index):\n",
    "    delay = 0.1  # Start with 500ms\n",
    "    max_retries = 5\n",
    "\n",
    "    model_id = model_dataset_df.iloc[index][\"modelId\"]\n",
    "\n",
    "    # Fetch metadata with exponential backoff\n",
    "    for _ in range(max_retries):\n",
    "        try:\n",
    "            metadata = api.model_info(model_id).__dict__\n",
    "            model_dataset_df.at[index, \"metadata\"] = metadata\n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if \"404\" in str(e):\n",
    "                print(f\"Model {model_id} not found, skipping...\")\n",
    "                metadata = None\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Error fetching metadata: {e}, backing off for {delay:.2f}s...\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2\n",
    "    else:\n",
    "        print(f\"Failed to fetch metadata for model {model_id} after {max_retries} retries.\")\n",
    "        metadata = None\n",
    "\n",
    "    # Wait for 1/5 of a second before fetching the model card\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    # Fetch model card with exponential backoff\n",
    "    delay = 0.5  # Reset delay for model card fetching\n",
    "    for _ in range(max_retries):\n",
    "        try:\n",
    "            model_card = ModelCard.load(model_id)\n",
    "            model_dataset_df.at[index, \"model_card\"] = model_card\n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if \"404\" in str(e):\n",
    "                print(f\"Model {model_id} not found, skipping...\")\n",
    "                model_card = None\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Error fetching model card: {e}, backing off for {delay:.2f}s...\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2\n",
    "    else:\n",
    "        print(f\"Failed to fetch model card for model {model_id} after {max_retries} retries.\")\n",
    "        model_card = None\n",
    "\n",
    "    # Write the results to the CSV file\n",
    "    write_to_csv(index, model_id, model_dataset_df.at[index, \"fullJson\"], metadata, model_card)\n",
    "\n",
    "# Initialize the CSV file with headers\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"index\",\"modelId\",\"fullJson\", \"Metadata\", \"ModelCard\"])\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize the process\n",
    "MAX_WORKERS_THREAD = 20\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS_THREAD) as executor:\n",
    "    futures = [executor.submit(fetch_metadata_and_model_card, i) for i in range(len(model_dataset_df))]\n",
    "    for i, future in enumerate(as_completed(futures), 1):\n",
    "        try:\n",
    "            future.result()  # To raise any exceptions caught during execution\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing future {i}: {e}\")\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Completed {i}/{len(futures)} tasks\")\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "    for future in as_completed(futures):\n",
    "        future.result()  # To raise any exceptions caught during execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
