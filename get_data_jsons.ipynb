{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c22760",
   "metadata": {},
   "source": [
    "# Getting all model JSONs\n",
    "\n",
    "Here we attempt to scrape the models API for the fine-tuning relationship for all models. To do so, we use the model API. \n",
    "\n",
    "The following link: https://huggingface.co/api/models\n",
    "provides a list of json values with the following format:\n",
    "[{\n",
    "    \"_id\": \"687060f05721fba56ca177a8\",\n",
    "    \"id\": \"moonshotai/Kimi-K2-Instruct\",\n",
    "    \"likes\": 472,\n",
    "    \"trendingScore\": 472,\n",
    "    \"private\": false,\n",
    "    \"downloads\": 13356,\n",
    "    \"tags\": [\n",
    "      \"transformers\",\n",
    "      \"safetensors\",\n",
    "      \"kimi_k2\",\n",
    "      \"text-generation\",\n",
    "      \"conversational\",\n",
    "      \"custom_code\",\n",
    "      \"doi:10.57967/hf/5976\",\n",
    "      \"license:other\",\n",
    "      \"autotrain_compatible\",\n",
    "      \"endpoints_compatible\",\n",
    "      \"fp8\",\n",
    "      \"region:us\"\n",
    "    ],\n",
    "    \"pipeline_tag\": \"text-generation\",\n",
    "    \"library_name\": \"transformers\",\n",
    "    \"createdAt\": \"2025-07-11T00:55:12.000Z\",\n",
    "    \"modelId\": \"moonshotai/Kimi-K2-Instruct\"\n",
    "  },\n",
    "  {\n",
    "    \"_id\": \"685ffb0a9c4d599d2a98bc2c\",\n",
    "    \"id\": \"THUDM/GLM-4.1V-9B-Thinking\",\n",
    "    \"likes\": 568,\n",
    "    \"trendingScore\": 368,\n",
    "    \"private\": false,\n",
    "    \"downloads\": 33839,\n",
    "    \"tags\": [\n",
    "      \"transformers\",\n",
    "      \"safetensors\",\n",
    "      \"glm4v\",\n",
    "      \"image-text-to-text\",\n",
    "      \"reasoning\",\n",
    "      \"conversational\",\n",
    "      \"en\",\n",
    "      \"zh\",\n",
    "      \"arxiv:2507.01006\",\n",
    "      \"base_model:THUDM/GLM-4-9B-0414\",\n",
    "      \"base_model:finetune:THUDM/GLM-4-9B-0414\",\n",
    "      \"license:mit\",\n",
    "      \"endpoints_compatible\",\n",
    "      \"region:us\"\n",
    "    ],\n",
    "    \"pipeline_tag\": \"image-text-to-text\",\n",
    "    \"library_name\": \"transformers\",\n",
    "    \"createdAt\": \"2025-06-28T14:24:10.000Z\",\n",
    "    \"modelId\": \"THUDM/GLM-4.1V-9B-Thinking\"\n",
    "  }]\n",
    "\n",
    "  We'd like to use pagination to get all such models in the hub, and simply keep information on \"modelId\" and the full Json associated with that model, for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c104c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_all_models():\n",
    "    #url = \"https://huggingface.co/api/models\"\n",
    "    url = \"https://huggingface.co/api/models?sort=trendingScore&cursor=eyIkb3IiOlt7InRyZW5kaW5nU2NvcmUiOjAsIl9pZCI6eyIkZ3QiOiI2NzAyYTc0MDIzZGY1YTdiZDgxZDcxYzIifX0seyJ0cmVuZGluZ1Njb3JlIjp7IiRsdCI6MH19LHsidHJlbmRpbmdTY29yZSI6bnVsbH1dfQ%3D%3D\"\n",
    "    models = []\n",
    "    urls = []\n",
    "    #while True:\n",
    "    for i in range(1000):\n",
    "        print(i)\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            break\n",
    "        data = response.json()\n",
    "        if not data:\n",
    "            break\n",
    "        for model in data:\n",
    "            models.append({\"modelId\": model[\"modelId\"], \"fullJson\": model})\n",
    "        \n",
    "        # Check for the next page link in the response headers\n",
    "        next_page_link = response.headers.get('Link')\n",
    "        if not next_page_link or 'rel=\"next\"' not in next_page_link:\n",
    "            break\n",
    "        \n",
    "        # Extract the URL for the next page\n",
    "        url = next_page_link.split(';')[0].strip('<>')\n",
    "        urls.append(url)\n",
    "\n",
    "        #page += 1\n",
    "    return models, urls\n",
    "\n",
    "def create_model_dataset():\n",
    "    models, urls = fetch_all_models()\n",
    "    df = pd.DataFrame(models)\n",
    "    return df, urls\n",
    "\n",
    "# Create the dataset\n",
    "model_dataset_2, urls_2 = create_model_dataset()\n",
    "\n",
    "model_dataset_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bafdf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset_2.to_csv(\"data/ai_ecosystem_jsons_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
